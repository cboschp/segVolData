{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import patches, lines\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import math\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams[\"font.size\"] = \"10\"\n",
    "plt.rcParams[\"axes.labelsize\"] = \"10\"\n",
    "plt.rcParams[\"xtick.labelsize\"] = \"10\"\n",
    "plt.rcParams[\"ytick.labelsize\"] = \"10\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = Path(\"../data\")\n",
    "data_path_C432_XNH = data_path / \"C432_XNH_nuclei\"\n",
    "data_path_Y391_XNH = data_path / \"Y391_XNH_nuclei\"\n",
    "data_path_Y489_XNH = data_path / \"Y489_XNH_nuclei\"\n",
    "\n",
    "plots_path = Path(\"../plots\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_volume_per_vx = lambda scale: scale[0] * scale[1] * scale[2] / 1e9\n",
    "\n",
    "scale_C432_XNH_mag2 = np.array([100, 100, 100]) * 2\n",
    "scale_Y391_XNH_mag2 = np.array([100, 100, 100]) * 2\n",
    "scale_Y489_XNH_mag2 = np.array([100, 100, 100]) * 2\n",
    "\n",
    "volume_per_vx_C432_XNH_mag2 = get_volume_per_vx(scale_C432_XNH_mag2)\n",
    "volume_per_vx_Y391_XNH_mag2 = get_volume_per_vx(scale_Y391_XNH_mag2)\n",
    "volume_per_vx_Y489_XNH_mag2 = get_volume_per_vx(scale_Y489_XNH_mag2)\n",
    "\n",
    "get_diameter_for_volume = lambda volume: 2 * pow(3 * volume / (4 * math.pi), 1/3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Volume-sphericity plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_all_C432_XNH = data_path_C432_XNH / \"C432_XNH-v10-segv1-masked_nuclei_data_sphericity_vx.csv.gz\"\n",
    "data_true_positives_C432_XNH = data_path_C432_XNH / \"C432_XNH-eval-v10-segv1-18boxes_nuclei_true_positives_volumes_sphericities_vx.csv.gz\"\n",
    "data_false_positives_C432_XNH = data_path_C432_XNH / \"C432_XNH-eval-v10-segv1-18boxes_nuclei_false_positives_volumes_sphericities_vx.csv.gz\"\n",
    "data_thresholds_C432_XNH = data_path_C432_XNH / \"C432_XNH-v10-segv1_thresholds_volume_sphericity.csv\"\n",
    "\n",
    "data_all_Y391_XNH = data_path_Y391_XNH / \"Y391_XNH-v10-segv1-masked_nuclei_data_sphericity_vx.csv.gz\"\n",
    "data_true_positives_Y391_XNH = data_path_Y391_XNH / \"Y391_XNH-eval-v10-segv1_nuclei_true_positives_volumes_sphericities_vx.csv.gz\"\n",
    "data_false_positives_Y391_XNH = data_path_Y391_XNH / \"Y391_XNH-eval-v10-segv1_nuclei_false_positives_volumes_sphericities_vx.csv.gz\"\n",
    "data_thresholds_Y391_XNH = data_path_Y391_XNH / \"Y391_XNH-v10-segv1_thresholds_volume_sphericity.csv\"\n",
    "\n",
    "data_all_Y489_XNH = data_path_Y489_XNH / \"Y489_ID16A_v18-v13-29boxes-segv1-volume-masked-v2_nuclei_data_sphericity_vx.csv.gz\"\n",
    "data_true_positives_Y489_XNH = data_path_Y489_XNH / \"Y489_ID16A_v18-eval-v13-29boxes-segv1-testv3_nuclei_true_positives_volumes_sphericities_vx.csv.gz\"\n",
    "data_false_positives_Y489_XNH = data_path_Y489_XNH / \"Y489_ID16A_v18-eval-v13-29boxes-segv1-testv3_nuclei_false_positives_volumes_sphericities_vx.csv.gz\"\n",
    "data_thresholds_Y489_XNH = data_path_Y489_XNH / \"Y489_ID16A_v18-v13_thresholds_volume_sphericity.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scatter_volume_sphericity(ax, volume_per_vx, data_all_path, data_true_positives_path, data_false_positives_path, thresholds_path):\n",
    "    detected_nuclei = pd.read_csv(data_all_path, compression=\"gzip\")\n",
    "\n",
    "    segment_volumes = detected_nuclei[\"volumes\"] * volume_per_vx\n",
    "    sphericities = detected_nuclei[\"sphericities\"]\n",
    "    ax.set(xlabel=r\"volume in Âµm$^3$\", ylabel=\"sphericity\", xscale=\"log\", ylim=(0,3), xlim=(1E-2, 1.E7),xticks=[1.E-2, 1.E0, 1.E2, 1.E4, 1.E6,], yticks=np.arange(0, 4, 1))\n",
    "\n",
    "    # If the points are not rasterized, the resulting image file will become very large\n",
    "    print(segment_volumes.max())\n",
    "    ax.scatter(segment_volumes, sphericities, color=\"cyan\", label=\"all\", s=5, alpha=0.5, rasterized=True)\n",
    "   \n",
    "    nuclei_true_positives = pd.read_csv(data_true_positives_path, compression=\"gzip\")\n",
    "    nuclei_false_positives = pd.read_csv(data_false_positives_path, compression=\"gzip\")\n",
    "\n",
    "    eval_tp_volumes = nuclei_true_positives[\"volumes\"] * volume_per_vx\n",
    "    eval_tp_sphericities = nuclei_true_positives[\"sphericities\"]\n",
    "        \n",
    "    eval_fp_volumes = nuclei_false_positives[\"volumes\"] * volume_per_vx\n",
    "    eval_fp_sphericities = nuclei_false_positives[\"sphericities\"]\n",
    "                \n",
    "    ax.scatter(eval_tp_volumes, eval_tp_sphericities, color=\"blue\", label=\"true pos.\", s=5, alpha=0.8, rasterized=True)\n",
    "    ax.scatter(eval_fp_volumes, eval_fp_sphericities, color=\"orange\", label=\"false pos.\", s=5, alpha=0.8, rasterized=True)\n",
    "    ax.legend()\n",
    "        \n",
    "    thresholds_df = pd.read_csv(thresholds_path)\n",
    "    threshold_volume = thresholds_df[\"threshold_volume\"][0] * volume_per_vx\n",
    "    ax.axvline(threshold_volume, color=\"black\", linestyle=\"dashdot\", linewidth=1.5)\n",
    "    ax.annotate(\"volume thr.\", (threshold_volume + threshold_volume/10, 1.2), rotation=90)\n",
    "\n",
    "    threshold_sphericity = thresholds_df[\"threshold_sphericity\"][0]\n",
    "    ax.axhline(threshold_sphericity, color=\"black\", linestyle=\"dashdot\", linewidth=1.5)\n",
    "    ax.annotate(\"spher. thr.\", (1.E4, threshold_sphericity - 0.15))\n",
    "\n",
    "    ax.axhline(1, color=\"dimgray\", linestyle=\"dashdot\", linewidth=1.5)\n",
    "    ax.annotate(\"spher. = 1\", (1.E4, 0.85), color=\"dimgray\")\n",
    "    ax.legend(facecolor=\"None\")\n",
    "    ax.spines['right'].set_visible(False)\n",
    "    ax.spines['top'].set_visible(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(3, 3))\n",
    "ax = fig.add_subplot()\n",
    "scatter_volume_sphericity(ax, volume_per_vx_C432_XNH_mag2, data_all_C432_XNH, data_true_positives_C432_XNH, data_false_positives_C432_XNH, data_thresholds_C432_XNH)\n",
    "plt.savefig(plots_path/\"F3e_volumes_sphericities_thresholded_C432_XNH.svg\", format=\"svg\", dpi=300, bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(3, 3))\n",
    "ax = fig.add_subplot()\n",
    "scatter_volume_sphericity(ax, volume_per_vx_Y391_XNH_mag2, data_all_Y391_XNH, data_true_positives_Y391_XNH, data_false_positives_Y391_XNH, data_thresholds_Y391_XNH)\n",
    "plt.savefig(plots_path/\"F3k_volumes_sphericities_thresholded_Y391_XNH.svg\", format=\"svg\", dpi=300, bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(3, 3))\n",
    "ax = fig.add_subplot()\n",
    "scatter_volume_sphericity(ax, volume_per_vx_Y489_XNH_mag2, data_all_Y489_XNH, data_true_positives_Y489_XNH, data_false_positives_Y489_XNH, data_thresholds_Y489_XNH)\n",
    "plt.savefig(plots_path/\"F3q_volumes_sphericities_thresholded_Y489_XNH.svg\", format=\"svg\", dpi=300, bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Metrics per bounding box plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bbox_metrics_crossvalidation_C432_XNH = pd.read_csv(data_path_C432_XNH / \"C432_XNH-v10-segv1_metrics_volume_sphericity_threshold_cross_validation_boxes.csv\")\n",
    "bbox_metrics_test_C432_XNH = pd.read_csv(data_path_C432_XNH / \"C432_XNH-v10-segv1_metrics_volume_sphericity_threshold_test_boxes.csv\")\n",
    "\n",
    "bbox_metrics_crossvalidation_Y391_XNH = pd.read_csv(data_path_Y391_XNH / \"Y391_XNH-v10-segv1_metrics_volume_sphericity_threshold_cross_validation_boxes.csv\")\n",
    "bbox_metrics_test_Y391_XNH = pd.read_csv(data_path_Y391_XNH / \"Y391_XNH-v10-segv1_metrics_volume_sphericity_threshold_test_boxes.csv\")\n",
    "\n",
    "bbox_metrics_Y489_XNH = pd.read_csv(data_path_Y489_XNH / \"Y489_ID16A_v18_eval_v13_29boxes_segv1_testv3_metrics_volume_sphericity_threshold_test_boxes.csv\")\n",
    "test_box_names_Y489_XNH = [\"GL_border2\", \"MCL_border1\", \"GL_ctr3\", \"EPL_ctr1\", \"MCL_ctr2\", \"EPL_border3\"]\n",
    "bbox_metrics_classifier_selection_Y489_XNH = bbox_metrics_Y489_XNH[~bbox_metrics_Y489_XNH[\"box_name\"].isin(test_box_names_Y489_XNH)]\n",
    "bbox_metrics_test_Y489_XNH = bbox_metrics_Y489_XNH[bbox_metrics_Y489_XNH[\"box_name\"].isin(test_box_names_Y489_XNH)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scatter_precision_recall_per_box(ax, metrics_per_bbox_trainval, metrics_per_bbox_test, has_dark, trainval_label = \"cross-val.\"):\n",
    "    colors = {\"EPL\": \"#206Cffff\",\"MCL\": \"#595959ff\", \"GL\": \"#FF500Fff\"}\n",
    "    region_markers = {\"ctr\": \"s\", \"border\": \"^\", \"dark\": \"v\"} if has_dark else {\"ctr\": \"s\", \"border\": \"^\"}\n",
    "\n",
    "    def get_color_and_marker(box_name):\n",
    "        layer = re.findall(\"EPL|MCL|GL\", box_name)[0]\n",
    "        region = re.findall(\"ctr|border|dark\", box_name)[0]\n",
    "        return colors[layer], region_markers[region]\n",
    "    \n",
    "    box_name_without_number = lambda box_name: box_name[:-1] if box_name[-1].isnumeric() else box_name\n",
    "\n",
    "    for bbox_metrics_entry in metrics_per_bbox_trainval.itertuples():\n",
    "        box_name = bbox_metrics_entry.box_name\n",
    "        precision = bbox_metrics_entry.precision\n",
    "        recall = bbox_metrics_entry.recall_thresholding_and_classifier\n",
    "        color, marker = get_color_and_marker(box_name_without_number(box_name))\n",
    "        ax.scatter(precision, recall, color=color, marker=marker, s=50, facecolors=\"None\")\n",
    "    \n",
    "    for bbox_metrics_entry in metrics_per_bbox_test.itertuples():\n",
    "        box_name = bbox_metrics_entry.box_name\n",
    "        precision = bbox_metrics_entry.precision\n",
    "        recall = bbox_metrics_entry.recall_thresholding_and_classifier\n",
    "        color, marker = get_color_and_marker(box_name_without_number(box_name))\n",
    "        ax.scatter(precision, recall, color=\"black\", marker=marker, s=50, facecolors=color)\n",
    "        \n",
    "    ax.set(xticks=np.arange(0, 1.1, 0.25), xlabel=\"precision\", xlim=(0, 1.1),\n",
    "           yticks=np.arange(0, 1.1, 0.25), ylabel=\"recall\", ylim=(0, 1.1))\n",
    "    \n",
    "    patch_crossval = patches.Patch(label=trainval_label, edgecolor=\"black\", facecolor=\"None\", linewidth=1, linestyle=\"-\")\n",
    "    patch_test = patches.Patch(color=\"black\", label=\"test\")\n",
    "    patches_splits = [patch_crossval, patch_test]\n",
    "    markers_regions = [lines.Line2D([], [], marker=marker, label=region, linestyle=\"none\", color=\"black\") for region, marker in region_markers.items()]\n",
    "    patches_layers = [patches.Patch(color=color, label=layer) for layer, color in colors.items()]\n",
    "    ax.legend(loc=\"upper left\", handles=markers_regions + patches_splits + patches_layers, facecolor=\"None\")\n",
    "\n",
    "    ax.spines['right'].set_visible(False)\n",
    "    ax.spines['top'].set_visible(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(3, 3))\n",
    "ax = fig.add_subplot()\n",
    "scatter_precision_recall_per_box(ax, bbox_metrics_crossvalidation_C432_XNH, bbox_metrics_test_C432_XNH, has_dark=False)\n",
    "plt.savefig(plots_path/\"F3f_v3_metrics_boxes_thresholded_C432_XNH.svg\", format=\"svg\", bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(3, 3))\n",
    "ax = fig.add_subplot()\n",
    "scatter_precision_recall_per_box(ax, bbox_metrics_crossvalidation_Y391_XNH, bbox_metrics_test_Y391_XNH, has_dark=False)\n",
    "plt.savefig(plots_path/\"F3l_v3_metrics_boxes_thresholded_Y391_XNH.svg\", format=\"svg\", bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(3, 3))\n",
    "ax = fig.add_subplot()\n",
    "scatter_precision_recall_per_box(ax, bbox_metrics_classifier_selection_Y489_XNH, bbox_metrics_test_Y489_XNH, has_dark=True, trainval_label=\"class.sel.\")\n",
    "plt.savefig(plots_path/\"F3r_v3_metrics_boxes_thresholded_Y489_XNH.svg\", format=\"svg\", bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plots to compare training data amounts for Y489_XNH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores_path = data_path_Y489_XNH / \"compare_Y489_train_data_amount.csv\"\n",
    "\n",
    "filtered_nuclei_paths_v13 = {}\n",
    "\n",
    "filtered_nuclei_path_v11 = data_path_Y489_XNH / \"Y489_ID16A_v18-v11-segv1-volume-masked-v2_nuclei_data_sphericity_vx_filtered_nuclei_data_sphericity_vx.csv.gz\"\n",
    "\n",
    "for i in range(5, 30, 6): \n",
    "    filtered_nuclei_paths_v13[i] = data_path_Y489_XNH / f\"Y489_ID16A_v18-v13-{i}boxes-segv1-volume-masked-v2_nuclei_data_sphericity_vx_filtered_nuclei_data_sphericity_vx.csv.gz\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_train_data_scores(path, ax):\n",
    "    data = pd.read_csv(path)\n",
    "    for i, row in data.iterrows():\n",
    "        if row[\"contains_C432_train_data\"]:\n",
    "            data.at[i, \"contains_C432_train_data\"] = 30\n",
    "    data[\"sum_bboxes\"] = data[\"bboxes_Y489\"] + data[\"contains_C432_train_data\"]\n",
    "    data[\"percentage_Y489\"] = 1 - (data[\"contains_C432_train_data\"] / data[\"sum_bboxes\"])\n",
    "    x_lables = [\"0+29\", \"30+0\", \"30+5\", \"30+11\", \"30+17\", \"30+23\", \"30+29\"]\n",
    "    data = data.sort_values(\"sum_bboxes\")\n",
    "\n",
    "    color_blend = data[\"percentage_Y489\"].apply(lambda x: (0, 1-x, x))\n",
    "\n",
    "    for i, score in enumerate([\"precision\", \"recall\", \"f1\"]):\n",
    "        ax[i].set(ylim=(0.795, 1.005), xlim=(25, 65), ylabel=score)\n",
    "        \n",
    "        ax[i].set(xticks=[30, 40, 50, 60])\n",
    "        ax[i].set(yticks=[0.8, 0.9, 1.0])\n",
    "        ax[i].tick_params(axis='x', rotation=60)\n",
    "        ax[i].scatter(data[\"sum_bboxes\"], data[score], color=color_blend)\n",
    "        for j, txt in enumerate(x_lables):\n",
    "            ax[i].annotate(txt, (data[\"sum_bboxes\"].iloc[j] + 0.5 , data[score].iloc[j] - 0.005), fontsize=14, rotation=60)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_absolute_numbers_filtered(ax, filtered_v13_paths):\n",
    "    data_v13 = {i: pd.read_csv(path, compression=\"gzip\") for i, path in filtered_v13_paths.items()}\n",
    "\n",
    "    region_sum = 0\n",
    "    diff_avg_nuclei_dict = {}\n",
    "    for i, data in data_v13.items():\n",
    "        num_nuclei = data.shape[0]\n",
    "        region_sum += num_nuclei\n",
    "        diff_avg_nuclei_dict[i] = num_nuclei\n",
    "    #divide all values by region_sum\n",
    "    diff_avg_nuclei_dict = {k: v-(region_sum/len(data_v13)) for k, v in diff_avg_nuclei_dict.items()}\n",
    "    ax.bar(diff_avg_nuclei_dict.keys(), diff_avg_nuclei_dict.values())\n",
    "    ax.set(xticks=[5, 11, 17, 23, 29])\n",
    "    ax.set(xlabel=\"Number of added Y489 training bboxes\", ylabel=f\"difference to average num of nuclei\")\n",
    "    ax.axhline(y=0, color='dimgray', linestyle='dashed')\n",
    "    ax.text(0.6, 0.6, f\"average: {round(region_sum/len(data_v13))}\", transform=ax.transAxes, color='dimgray')\n",
    "   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(2,2))\n",
    "ax = fig.add_subplot()\n",
    "plot_absolute_numbers_filtered(ax, filtered_nuclei_paths_v13)\n",
    "plt.savefig(plots_path/\"F3c_compare_absolute_difference.svg\", format=\"svg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "plt.rcParams[\"font.size\"] = \"24\"\n",
    "plt.rcParams[\"axes.labelsize\"] = \"24\"\n",
    "plt.rcParams[\"xtick.labelsize\"] = \"24\"\n",
    "plt.rcParams[\"ytick.labelsize\"] = \"24\"\n",
    "\n",
    "ncols = 3\n",
    "nrows = 1\n",
    "subplot_size = 4\n",
    "fig, ax = plt.subplots(nrows, ncols, figsize=(ncols * subplot_size, nrows * subplot_size), constrained_layout=True)\n",
    "fig.supxlabel(\"Number of train bboxes C432 + Y489\")\n",
    "plot_train_data_scores(scores_path, ax)\n",
    "plt.savefig(plots_path/\"F3c_compare_added_training_data.svg\", format=\"svg\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
